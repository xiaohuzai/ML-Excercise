{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 数据读取与计算\n",
    "import pandas as  pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 数据预处理与模型选择\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_auc_score, roc_curve, recall_score, classification_report\n",
    "import itertools\n",
    "\n",
    "# 随机森林与SVM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bdry = False\n",
    "show_best_c = False\n",
    "# 对所有特征做标准化处理，或者对Amount做\n",
    "def normalize_feature(data, amount_only = False):\n",
    "    if amount_only:\n",
    "        data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
    "    else:\n",
    "        for feature in data.columns[:-1]:\n",
    "            data[feature] = StandardScaler().fit_transform(data[feature].values.reshape(-1,1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据被切分成训练集和测试集\n",
    "def split_train_test(fraud_indices, normal_indices, test_size = 0.3):\n",
    "    number_records_fraud = len(fraud_indices)\n",
    "    number_records_normal = len(normal_indices)\n",
    "    test_fraud_end = int(number_records_fraud * test_size)\n",
    "    test_normal_end = int(number_records_normal  * test_size)\n",
    "\n",
    "    test_fraud_indices = fraud_indices[0:test_fraud_end]\n",
    "    train_fraud_indices = fraud_indices[test_fraud_end:]\n",
    "\n",
    "    test_normal_indices = normal_indices[0:test_normal_end]\n",
    "    train_normal_indices = normal_indices[test_normal_end:]\n",
    "\n",
    "    return train_normal_indices, train_fraud_indices, test_normal_indices, test_fraud_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集做下采样\n",
    "def getTrainingSample(train_fraud_indices, train_normal_indices, data, train_normal_pos, ratio):\n",
    "    train_number_records_fraud = int(ratio*len(train_fraud_indices))\n",
    "    train_number_records_normal = len(train_normal_indices)\n",
    "    if train_normal_pos + train_number_records_fraud <= train_number_records_normal:\n",
    "        small_train_normal_indices = train_normal_indices[train_normal_pos: train_normal_pos + train_number_records_fraud]\n",
    "        train_normal_pos = train_normal_pos + train_number_records_fraud\n",
    "    else:\n",
    "        small_train_normal_indices = np.concatenate([train_normal_indices[train_normal_pos: train_number_records_normal],train_normal_indices[0: train_normal_pos + train_number_records_fraud- train_number_records_normal]])\n",
    "        train_normal_pos = train_normal_pos + train_number_records_fraud - train_number_records_normal\n",
    "\n",
    "    under_train_sample_indices = np.concatenate([train_fraud_indices, small_train_normal_indices])\n",
    "    np.random.shuffle(under_train_sample_indices)\n",
    "    # 下采样\n",
    "    under_train_sample_data = data.iloc[under_train_sample_indices,:]\n",
    "\n",
    "    X_train_undersample = under_train_sample_data.ix[:, under_train_sample_data.columns != 'Class']\n",
    "    y_train_undersample = under_train_sample_data.ix[:, under_train_sample_data.columns == 'Class']\n",
    "\n",
    "    return X_train_undersample, y_train_undersample, train_normal_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最简单的KNN模型\n",
    "def knn_module(X, y, indices, c_param, bdry = None):\n",
    "    knn = KNeighborsClassifier(n_neighbors = c_param)\n",
    "    knn.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n",
    "    y_pred_undersample = knn.predict(X.iloc[indices[1],:].values)\n",
    "    return y_pred_undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加RBF核的svm\n",
    "def svm_rbf_module(X, y, indices, c_param, bdry = 0.5):\n",
    "    svm_rbf = SVC(C=c_param, probability = True)\n",
    "    svm_rbf.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n",
    "    y_pred_undersample = svm_rbf.predict_proba(X.iloc[indices[1],:].values)[:,1]>=bdry\n",
    "    return y_pred_undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加多项式核的svm\n",
    "def svm_poly_module(X, y, indices, c_param, bdry = 0.5):\n",
    "    svm_poly = SVC(C= c_param[0], kernel = 'poly', degree = c_param[1], probability = True)\n",
    "    svm_poly.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n",
    "    y_pred_undersample = svm_poly.predict_proba(X.iloc[indices[1],:].values)[:,1]>=bdry\n",
    "    return y_pred_undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逻辑回归\n",
    "def lr_module(X, y, indices, c_param, bdry = 0.5):\n",
    "    lr = LogisticRegression(C = c_param, penalty = 'l1')\n",
    "    lr.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n",
    "    y_pred_undersample= lr.predict_proba(X.iloc[indices[1],:].values)[:,1]>=bdry\n",
    "    return y_pred_undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机森林\n",
    "def rf_module(X, y, indices, c_param, bdry = 0.5):\n",
    "    rf = RandomForestClassifier(n_jobs=-1, n_estimators = 100, criterion = 'entropy', max_features = 'auto', max_depth = None, min_samples_split  = c_param, random_state=0)\n",
    "    rf.fit(X.iloc[indices[0],:], y.iloc[indices[0],:].values.ravel())\n",
    "    y_pred_undersample = rf.predict_proba(X.iloc[indices[1],:].values)[:,1]>=bdry\n",
    "    return y_pred_undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算召回率和auc\n",
    "# y_t 是真实的标签，y_p是预测结果\n",
    "def compute_recall_and_auc(y_t, y_p):\n",
    "    # 混淆矩阵\n",
    "    cnf_matrix = confusion_matrix(y_t,y_p)\n",
    "    np.set_printoptions(precision = 2)\n",
    "    recall_score = cnf_matrix[1,1]/(cnf_matrix[1,0] + cnf_matrix[1,1])\n",
    "\n",
    "    # ROC曲线与auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_t, y_p)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    return recall_score, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 很粗暴地用遍历的方式去寻找最优参数组\n",
    "# 实际上大家可以用sklearn当中的GridSearchCV写出更优雅的代码\n",
    "def cross_validation_recall(x_train_data,y_train_data, c_param_range, models_dict, model_name):\n",
    "    fold = KFold(len(y_train_data),5, shuffle=False)\n",
    "\n",
    "    results_table = pd.DataFrame(index = range(len(c_param_range),2), columns = ['C_parameter','Mean recall score'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "\n",
    "    recall_mean = []\n",
    "    for c_param in c_param_range:\n",
    "        recall_accs = []\n",
    "        for iteration, indices in enumerate(fold, start = 1):\n",
    "\n",
    "            y_pred_undersample = models_dict[model_name](x_train_data, y_train_data, indices, c_param)\n",
    "\n",
    "            recall_acc, _ = compute_recall_and_auc(y_train_data.iloc[indices[1],:].values, y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "\n",
    "        recall_mean.append(np.mean(recall_accs))\n",
    "\n",
    "    results_table['Mean recall score'] = recall_mean\n",
    "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
    "\n",
    "    return best_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同的决策边界阈值\n",
    "# 也是通过遍历调参的方式去确定\n",
    "def decision_boundary(x_train_data,y_train_data, fold,  best_c, bdry_dict, models_dict, model_name):\n",
    "    bdry_ranges = [0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "    results_table = pd.DataFrame(index = range(len(bdry_ranges),2), columns = ['C_parameter','Mean recall score * auc'])\n",
    "    results_table['Bdry_params'] = bdry_ranges\n",
    "\n",
    "    recall_mean = []\n",
    "    for bdry in bdry_ranges:\n",
    "        recall_accs_aucs = []\n",
    "        for iteration, indices in enumerate(fold, start = 1):\n",
    "            y_pred_undersample = models_dict[model_name](x_train_data, y_train_data, indices, best_c, bdry)\n",
    "            recall_acc, roc_auc = compute_recall_and_auc(y_train_data.iloc[indices[1],:].values, y_pred_undersample)\n",
    "            recall_accs_aucs.append(bdry_dict[model_name](recall_acc, roc_auc))\n",
    "        recall_mean.append(np.mean(recall_accs_aucs))\n",
    "\n",
    "    results_table['Mean recall score * auc'] = recall_mean\n",
    "    best_bdry = results_table.loc[results_table['Mean recall score * auc'].idxmax()]['Bdry_params']\n",
    "\n",
    "    return best_bdry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 真正的建模与预测部分\n",
    "def model(X, y, train, bdry_dict = None, best_c = None, best_bdry = None, models = None, mode = None):\n",
    "    # 训练阶段\n",
    "    if train:\n",
    "        # 用不同的模型\n",
    "        models_dict = {'knn' : knn_module, 'svm_rbf': svm_rbf_module, 'svm_poly': svm_poly_module,\n",
    "                        'lr': lr_module, 'rf': rf_module}\n",
    "\n",
    "        # knn取不同的k值(超参数)\n",
    "        c_param_range_knn = [3,5,7,9]\n",
    "        best_c_knn = cross_validation_recall(X, y, c_param_range_knn, models_dict, 'knn')\n",
    "\n",
    "        # SVM中不同的参数\n",
    "        c_param_range_svm_rbf = [0.01, 0.1, 1, 10, 100]\n",
    "        best_c_svm_rbf = cross_validation_recall(X, y, c_param_range_svm_rbf, models_dict, 'svm_rbf')\n",
    "        c_param_range_svm_poly = [[0.01, 2], [0.01, 3], [0.01, 4], [0.01, 5], [0.01, 6], [0.01, 7], [0.01, 8], [0.01, 9],\n",
    "                                  [0.1, 2], [0.1, 3], [0.1, 4], [0.1, 5], [0.1, 6], [0.1, 7], [0.1, 8], [0.1, 9],\n",
    "                                  [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [1, 7], [1, 8], [1, 9],\n",
    "                                  [10, 2], [10, 3], [10, 4], [10, 5], [10, 6], [10, 7], [10, 8], [10, 9],\n",
    "                                  [100, 2], [100, 3], [100, 4], [100, 5], [100, 6], [100, 7], [100, 8], [100, 9]]\n",
    "\n",
    "        best_c_svm_poly = cross_validation_recall(X, y, c_param_range_svm_poly, models_dict, 'svm_poly')\n",
    "\n",
    "        # 逻辑回归当中的正则化强度\n",
    "        c_param_range_lr = [0.01,0.1,1,10,100]\n",
    "        best_c_lr = cross_validation_recall(X, y, c_param_range_lr, models_dict, 'lr')\n",
    "        \n",
    "        # 随机森林里调参\n",
    "        c_param_range_rf = [2, 5, 10, 15, 20]\n",
    "        best_c_rf = cross_validation_recall(X, y, c_param_range_rf, models_dict, 'rf')\n",
    "        best_c = [best_c_knn, best_c_svm_rbf, best_c_svm_poly, best_c_lr, best_c_rf, best_c]\n",
    "\n",
    "        # 交叉验证确定合适的决策边界阈值\n",
    "        # auc 和 召回率存储在bdry_dict之中.\n",
    "        fold = KFold(len(y), 4 ,shuffle=True) \n",
    "        \n",
    "        best_bdry_svm_rbf= decision_boundary(X, y, fold, best_c_svm_rbf, bdry_dict, models_dict, 'svm_rbf')\n",
    "        best_bdry_svm_poly = decision_boundary(X, y, fold, best_c_svm_poly, bdry_dict, models_dict, 'svm_poly')\n",
    "        best_bdry_lr = decision_boundary(X, y, fold, best_c_lr, bdry_dict, models_dict, 'lr')\n",
    "        best_bdry_rf = decision_boundary(X, y, fold, best_c_lr, bdry_dict, models_dict, 'rf')\n",
    "        best_bdry = [0.5, best_bdry_svm_rbf, best_bdry_svm_poly, best_bdry_lr, best_bdry_rf]\n",
    "\n",
    "        # 最优参数建模\n",
    "        knn = KNeighborsClassifier(n_neighbors = int(best_c_knn))\n",
    "        knn.fit(X.values, y.values.ravel())\n",
    "\n",
    "        svm_rbf = SVC(C=best_c_svm_rbf, probability = True)\n",
    "        svm_rbf.fit(X.values, y.values.ravel())\n",
    "\n",
    "        svm_poly = SVC(C=best_c_svm_poly[0], kernel = 'poly', degree = best_c_svm_poly[1], probability = True)\n",
    "        svm_poly.fit(X.values, y.values.ravel())\n",
    "\n",
    "        lr = LogisticRegression(C = best_c_lr, penalty ='l1', warm_start = False)\n",
    "        lr.fit(X.values, y.values.ravel())\n",
    "\n",
    "        rf = RandomForestClassifier(n_jobs=-1, n_estimators = 100, criterion = 'entropy', max_features = 'auto', max_depth = None, min_samples_split  = int(best_c_rf), random_state=0)\n",
    "        rf.fit(X.values, y.values.ravel())\n",
    "\n",
    "        models = [knn, svm_rbf, svm_poly, lr, rf]\n",
    "\n",
    "        return best_c, best_bdry, models\n",
    "    \n",
    "    # 预测阶段\n",
    "    else:\n",
    "        [knn, svm_rbf, svm_poly, lr, rf] = models\n",
    "        [_, best_bdry_svm_rbf, best_bdry_svm_poly, best_bdry_lr, best_bdry_rf] = best_bdry\n",
    "\n",
    "        # KNN\n",
    "        y_pred_knn = knn.predict(X.values)\n",
    "        # 用rbf核的SVM\n",
    "        y_pred_svm_rbf = svm_rbf.predict_proba(X.values)[:,1] >= best_bdry_svm_rbf\n",
    "        # 用多项式核的SVM\n",
    "        y_pred_svm_poly = svm_poly.predict_proba(X.values)[:,1] >= best_bdry_svm_poly\n",
    "        # LR\n",
    "        y_pred_lr= lr.predict_proba(X.values)[:,1] >= best_bdry_lr\n",
    "        # 随机森林\n",
    "        y_pred_rf = rf.predict_proba(X.values)[:,1] >= best_bdry_rf\n",
    "\n",
    "        x_of_three_models = {'knn' : y_pred_knn, 'svm_rbf' : y_pred_svm_rbf, 'svm_poly' : y_pred_svm_poly, 'lr' : y_pred_lr, 'rf': y_pred_rf}\n",
    "        X_5_data = pd.DataFrame(data = x_of_three_models)\n",
    "\n",
    "        y_pred= np.sum(X_5_data, axis = 1)>=mode\n",
    "\n",
    "        y_pred_lr_controls = []\n",
    "        params = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "\n",
    "        # 投票器去产出最终结果\n",
    "        for param in params:\n",
    "            y_pred_lr_controls.append(lr.predict_proba(X.values)[:,1] >= param)\n",
    "        return y_pred, y_pred_lr_controls, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总程序\n",
    "def run(data, mode, ratio, iteration1, bdry_dict):\n",
    "    recall_score_list =[]\n",
    "    auc_list = []\n",
    "    recall_score_lr_list =[]\n",
    "    auc_lr_list = []\n",
    "    best_c = None\n",
    "    best_bdry = None\n",
    "    for itr1 in range(iteration1):\n",
    "        #print(\"percentage: %.2f\" %(itr1/iteration1*100))\n",
    "\n",
    "        # 欺诈类的样本\n",
    "        fraud_indices = np.array(data[data.Class == 1].index)\n",
    "        np.random.shuffle(fraud_indices)\n",
    "\n",
    "        # 正常类的样本\n",
    "        normal_indices = np.array(data[data.Class == 0].index)\n",
    "        np.random.shuffle(normal_indices)\n",
    "\n",
    "        # 训练集与测试集\n",
    "        train_normal_indices, train_fraud_indices, test_normal_indices, test_fraud_indices = split_train_test(\n",
    "                                                                                            fraud_indices, normal_indices)\n",
    "        test_indices = np.concatenate([test_normal_indices,test_fraud_indices])\n",
    "\n",
    "        test_data = data.iloc[test_indices,:]\n",
    "        X_test = test_data.ix[:, test_data.columns != 'Class']\n",
    "        y_test = test_data.ix[:, test_data.columns == 'Class'].values.ravel()\n",
    "\n",
    "        # 数据下采样\n",
    "        X_train_undersample, y_train_undersample, train_normal_pos = getTrainingSample(\n",
    "                                                                    train_fraud_indices, train_normal_indices, data, 0, ratio)\n",
    "\n",
    "        # 训练模型\n",
    "        best_c, best_bdry, models = model(X_train_undersample, y_train_undersample, train = True,\n",
    "                                          bdry_dict = bdry_dict, best_c = best_c, best_bdry = best_bdry)\n",
    "\n",
    "        if show_best_c:\n",
    "            print(\"超参数值:\")\n",
    "            print(\"k-nearest nbd: %.2f, svm (rbf kernel): [%.2f, %.2f], svm (poly kernel): %.2f, logistic reg: %.2f, random forest: %.2f\"\n",
    "                  %(best_c[0], best_c[1], best_c[2][0], best_c[2][1], best_c[3], best_c[4]))\n",
    "\n",
    "        if show_bdry:\n",
    "            print(\"决策边界阈值:\")\n",
    "            print(\"k-nearest nbd: %.2f, svm (rbf kernel): %.2f, svm (poly kernel): %.2f, logistic reg: %.2f, random forest: %.2f\"\n",
    "                  %(best_bdry[0], best_bdry[1], best_bdry[2], best_bdry[3], best_bdry[4]))\n",
    "\n",
    "        # 预测\n",
    "        y_pred, y_pred_lr_controls, params = model(X_test, y_test, train = False, bdry_dict = None,\n",
    "                                                   best_c = best_c, best_bdry = best_bdry, models = models, mode = mode)\n",
    "\n",
    "        # 记录指标\n",
    "        recall_score, roc_auc = compute_recall_and_auc(y_test, y_pred)\n",
    "        recall_score_list.append(recall_score)\n",
    "        auc_list.append(roc_auc)\n",
    "\n",
    "        control_recall_all_param = []\n",
    "        control_roc_all_param = []\n",
    "        for i in range(len(params)):\n",
    "            recall_score_lr, roc_auc_lr = compute_recall_and_auc(y_test, y_pred_lr_controls[i]) # for control\n",
    "            control_recall_all_param.append(recall_score_lr)\n",
    "            control_roc_all_param.append(roc_auc_lr)\n",
    "\n",
    "        recall_score_lr_list.append(control_recall_all_param)\n",
    "        auc_lr_list.append(control_roc_all_param)\n",
    "\n",
    "    # 平均得分\n",
    "    mean_recall_score = np.mean(recall_score_list)\n",
    "    std_recall_score = np.std(recall_score_list)\n",
    "\n",
    "    mean_auc= np.mean(auc_list)\n",
    "    std_auc = np.std(auc_list)\n",
    "\n",
    "    mean_recall_score_lr = np.mean(recall_score_lr_list, axis = 0)\n",
    "    std_recall_score_lr = np.std(recall_score_lr_list, axis = 0)\n",
    "    mean_auc_lr= np.mean(auc_lr_list, axis = 0)\n",
    "    std_auc_lr = np.std(auc_lr_list, axis = 0)\n",
    "\n",
    "    result = [mean_recall_score, std_recall_score, mean_auc, std_auc]\n",
    "    control = [mean_recall_score_lr, std_recall_score_lr, mean_auc_lr, std_auc_lr]\n",
    "    return result, control, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些基本参数设定\n",
    "mode = 2\n",
    "ratio = 1\n",
    "iteration1 = 100\n",
    "show_best_c = True\n",
    "show_bdry = True\n",
    "\n",
    "def lr_bdry_module(recall_acc, roc_auc):\n",
    "    return 0.9*recall_acc+0.1*roc_auc\n",
    "def svm_rbf_bdry_module(recall_acc, roc_auc):\n",
    "    return recall_acc*roc_auc\n",
    "def svm_poly_bdry_module(recall_acc, roc_auc):\n",
    "    return recall_acc*roc_auc\n",
    "def rf_bdry_module(recall_acc, roc_auc):\n",
    "    return 0.5*recall_acc+0.5*roc_auc\n",
    "\n",
    "bdry_dict = {'lr': lr_bdry_module,'svm_rbf': svm_rbf_bdry_module,\n",
    "             'svm_poly': svm_poly_bdry_module, 'rf': rf_bdry_module}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [0.01, 0.10], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.50, svm (poly kernel): 0.30, logistic reg: 0.35, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.50, svm (poly kernel): 0.30, logistic reg: 0.30, random forest: 0.40\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [100.00, 100.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.50, svm (poly kernel): 0.30, logistic reg: 0.30, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 2.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.40, svm (poly kernel): 0.45, logistic reg: 0.35, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 2.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.35, svm (poly kernel): 0.30, logistic reg: 0.30, random forest: 0.35\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 10.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 2.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.30, svm (poly kernel): 0.35, logistic reg: 0.30, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 10.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 2.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.45, svm (poly kernel): 0.30, logistic reg: 0.40, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 2.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.45, svm (poly kernel): 0.30, logistic reg: 0.45, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [100.00, 10.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.50, svm (poly kernel): 0.30, logistic reg: 0.30, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 2.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.35, svm (poly kernel): 0.30, logistic reg: 0.35, random forest: 0.45\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [100.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.35, svm (poly kernel): 0.30, logistic reg: 0.40, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.30, svm (poly kernel): 0.30, logistic reg: 0.35, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.50, svm (poly kernel): 0.30, logistic reg: 0.35, random forest: 0.35\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [0.01, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.40, svm (poly kernel): 0.30, logistic reg: 0.35, random forest: 0.35\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 10.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.50, svm (poly kernel): 0.35, logistic reg: 0.40, random forest: 0.45\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [10.00, 1.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 5.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.40, svm (poly kernel): 0.30, logistic reg: 0.30, random forest: 0.40\n",
      "超参数值:\n",
      "k-nearest nbd: 3.00, svm (rbf kernel): [100.00, 10.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 10.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.45, svm (poly kernel): 0.30, logistic reg: 0.40, random forest: 0.30\n",
      "超参数值:\n",
      "k-nearest nbd: 5.00, svm (rbf kernel): [100.00, 10.00], svm (poly kernel): 2.00, logistic reg: 0.01, random forest: 2.00\n",
      "决策边界阈值:\n",
      "k-nearest nbd: 0.50, svm (rbf kernel): 0.45, svm (poly kernel): 0.30, logistic reg: 0.30, random forest: 0.30\n"
     ]
    }
   ],
   "source": [
    "# 读数据\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data = data.drop(['Time'], axis = 1)\n",
    "data = normalize_feature(data, amount_only = True)\n",
    "\n",
    "# 总体开始跑\n",
    "result, control, params = run(data = data, mode = mode, ratio = ratio, iteration1 = iteration1, bdry_dict = bdry_dict)\n",
    "print(\"超参数值:\")\n",
    "print(\"比率为: \", ratio, \" 模式为: \", mode)\n",
    "print(\"knn, svm_rbf, svm_poly, lr 和 rf 投票产出的结果是:\")\n",
    "print(\"平均召回率为 \", result[0], \" 召回率标准差为 \", result[1])\n",
    "print(\"平均auc为 \", result[2], \" auc标准差为 \", result[3])\n",
    "print()\n",
    "print(\"调整逻辑回归不同的阈值\")\n",
    "print(\"我们把超过阈值的样本判定为positive(欺诈)\")\n",
    "for i, param in enumerate(params):\n",
    "    print(\"阈值\", param)\n",
    "    print(\"平均召回率 \", control[0][i], \" 召回率标准差 \", control[1][i])\n",
    "    print(\"平均auc为 \", control[2][i], \" auc标准差 \", control[3][i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

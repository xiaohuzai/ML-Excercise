# 第一章 机器学习概述与算法介绍

## 1 机器学习概念

**机器学习是什么？**

>研究的是计算机怎样模拟人类的学习行为，以获取新的知识或技能，并重新组织已有的知识结构使之不断改善自身。
>
>计算机从**数据**中学习出**规律**和**模式**，以应用在新数据上做预测的任务。

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B51.PNG)



**监督学习算法**：分类问题、回归类问题

**无监督学习算法**：聚类算法、强化学习

- 分类问题（监督学习）

  > - 根据数据样本上抽取出的**特征**，判定其属于**有限个类别**中的哪一个
  > - 垃圾邮件识别（结果类别：1、垃圾邮件  2、正常邮件）
  > - 文本情感褒贬分析（结果类别：1、褒  2、贬）
  > - 图像内容识别（结果类别：1、猫  2、狗  3、人  4、羊驼）


![分类问题的例子](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B52.PNG)

- 回归问题（监督学习）

  > - 根据数据样本上抽取出的特征，预测连续值结果
  > - 《芳华》票房值
  > - 魔都房价具体值
  > - 刘德华和吴彦祖的具体颜值得分


![回归分析的例子](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B53.PNG)

*分类问题相当于是做选择题，而回归问题则是做计算题。比如说要计算出刘德华的颜值为9.5，吴彦祖的颜值为9.7*

- 聚类问题（无监督学习）

  > - 根据数据样本上抽取出的特征，挖掘出数据的关联模式。
  > - 相似用户挖掘/社区发现
  > - 新闻聚类

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E5%BF%B54.PNG)

*与监督学习的重要区别是，给你的数据是没有标准答案的。手里有的只有社区用户行为，只有新闻数据。你要自己去找它们是否属于一类。*

- 强化问题

  > - 研究如何基于环境而行动，以取得最大化的预期利益
  > - 游戏“吃鸡”最高分如何获取
  > - 机器人完成任务

**监督学习和无监督学习是根据你手上拿到的数据的不同形态去定义的机器学习算法。**

- 监督学习：特征+标签
  >- 分类：离散个结果中做选择
  >- 回归：输出连续值结果


- 无监督学习：特征
  >- 聚类：抱团学习
  >- 关联规则


- 强化学习：从环境到行为映射的学习

*监督学习：就像小时候在学校里学习一样，老师给的练习题有正确的参考答案，根据自己做自己对答案，通过对题错题来提高对知识的理解。*

*无监督学习：手头上只有数据，没有参考答案的，需要探索性的从数据上得到分布模式。如聚类算法，挖掘的是哪些样本和哪些样本关联度较高。再如很经典的超市里啤酒与尿布的例子。*

## 2 机器学习基本流程与工作环节

机器学习的应用工作是围绕着**数据**与**算法**展开的

*数据的质和量对算法有很大影响*

**机器学习不同阶段与作用**

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B%E4%B8%8E%E5%B7%A5%E4%BD%9C%E7%8E%AF%E8%8A%821.PNG)

*数据预处理很重要且繁琐，60%-70%的时间会放在数据预处理上，20%-30%的时间放在模型学习和模型评估上*

*数据好坏决定了模型效果的上限，而使用不同的算法只是去逼近这个上限。就跟学习要有好的学习资料，学习资料里面不能有错题。*

数据驱动方法：数据+机器学习算法=预测模型

机器学习应用阶段

1、 数据预处理
   - 数据采样、数据切分、特征抽取、特征选择、降维

2、模型学习
   - 超参选择、交叉验证、结果评估、模型选择、模型训练

3、模型评估
   - 分类、回归、排序评估标准

4、模型上线

## 3 机器学习中的评估指标

### 机器学习的评估方法

机器学习的目标：**泛化能力强**！能很好地适用于<u>没见过的样本</u>。（错误率低，精度高）

*手头上没有未知的样本，如何进行可靠地评估？*将数据集分为“测试集”与“训练集”

<u>测试集（用于评估）应该与训练集（用于模型学习）“互斥”</u>

常见方法

> 留出法（hold-out）
>
> 交叉验证法（cross validation）
>
> 自助法

- **留出法**


![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%871.PNG)

*手头上有1000套题，如果需要衡量我通过这1000道题的学习后效果好不好，可以从这1000道题中抽取100道题作为测试集，把它封到袋子里，用来在学习后检测自己学的好不好。而其他的900道题是用来学习的。*

注意点：

> 保持数据分布一致性（例如：分层采样）
>
> *例如在电商里有一个观测维度为“性别”，对化妆品来说，女生比男生分布要多，7:3, 那么学习用的训练集和测试用的训练集都要保持住7:3的比例，不要打破。*
>
> 多次重复划分（例如：100次随机划分）
>
> 测试集不能太大、不能太小（例如：1/5~1/3）

- **K折交叉验证**

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%872.PNG)

*此案例中K=10。将数据集分为10份，轮番用其中一份作为测试集。用K个测试结果去平均，得到一个较为可靠地结果*

- **自助法（bootstrap）**

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%873.PNG)

*如果有1000道题，自助法是在1000道题中有放回的抽样1000次。最后得到的训练集也是1000个，但是数据分布会改变，会有重复的数据选中，也会有约0.368的样本没有被选择过，则1000道题中没有被抽中过得约占0.368的数据就可以作为测试集，可以衡量算法好不好。*

### 机器学习的评估度量标准

**性能度量（performance measure）**：是衡量模型**泛化能力**的数值评价标准，反映了当前问题（任务需求）

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%861.PNG)

*关于模型“好坏”的判断，不仅取决于算法和数据，还取决于当前任务需求。*

#### 分类问题的常用性能度量

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%862.PNG)

**对于二分类来说，还有一种分类性能度量标准：<u>二分类混淆矩阵</u>**



![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%863.PNG)

准确率：预测所有是正例的情况中，猜对的几率是多少？

召回率：真实为正例的样本中，有多少是被我找出来了？

使用F1值来把准确率和召回率两个指标融合在一起。

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%864.PNG)

式中β是一个权重。

**对于二分类，还有一种度量指标为AUC**

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%865.PNG)

x轴为 伪阳性率 = （伪阳性数量）/（伪阳性数量+真阴性数量）

y轴为 真阳性率 = （真阳性数量）/（真阳性数量+伪阴性数量）

类似于医生判断病人是否有病，越靠近左上判断越准，越靠近右下判断越不准。

ROC为二分类不同分类阈值下(x,y)点连成的线，AUC为该线与x轴包围的面积。 AUC越大，该分类器泛化能力越好。

#### 回归类问题常用性能度量

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%AF%84%E4%BC%B0%E5%BA%A6%E9%87%8F%E6%A0%87%E5%87%866.PNG)



## 4 机器学习算法一览

![](https://raw.githubusercontent.com/xiaohuzai/ML-Excercise/master/pictures/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95%E4%B8%80%E8%A7%881.png)


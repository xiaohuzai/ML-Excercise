# 第二章 线性回归与逻辑回归

## 线性模型、线性回归与广义线性回归

### 1 线性模型

![](C:\ML-Excercise\pictures\chapter2\线性模型1.png)

线性模型既可以用于**分类**问题又可以用于**回归类**问题。

> 在回归类问题当中，是通过属性值的一个线性组合直接去拟合连续值作为一个输出。
>
> 在分类问题中，利用属性值的线性组合来得到一条用于不同类别分类的决策边界。

线性模型在工业界应用非常广泛。它的可解释性非常好，我们可以清晰的看到我们为何做出这样的决定，哪一部分属性对最后的结果有贡献，贡献多大。在模型部署和上线之后如果出现一些问题的话，我们也非常好去查找问题出现的原因到底是什么，及时地去做一个修正。

### 2 线性回归

![](C:\ML-Excercise\pictures\chapter2\线性回归1.png)

线性回归一个简单的例子：

> 让一个六年级的孩子在**不问**同学具体**体重**多少的情况下，把班上同学按照体重从轻到重排队。如何去做？
>
> 他可能通过观察大家的**身高**和**体格**来将大家排队。因为在人们的经验中，身高越高体格越壮，那么这个人体重就会越大。也就是说身高和体格与体重可能存在正相关关系。
>
> ![](C:\ML-Excercise\pictures\chapter2\线性回归2.png)
>
>上图，蓝点为收集到的样本数据，表明身高和体重确实存在正相关关系。而线性回归就是试图通过一个线性的表达形式去拟合样本点的分布状况。

另外一个例子：房价预测

> 房子的面积和价格。通过一个线性的组合关系去拟合面积（x）与价格（y）的关系
>
> ![](C:\ML-Excercise\pictures\chapter2\线性回归3.png)
>
> 上图是一个一元线性回归，通过一个线性的组合关系去拟合面积（x）与价格（y）的关系。
>
> 而除了面积之外，还有许多种因素影响房子价格，如几居室、楼层、房子年数等。
>
> ![](C:\ML-Excercise\pictures\chapter2\线性回归4.png)
>
> 此时线性回归就不是一元了，而是多元。给每个变量一个权重去做一个组合，试图去预测最后一个结果（即房价）。
>
> ![](C:\ML-Excercise\pictures\chapter2\线性回归5.png)
>
> 上图是一个二元线性回归模型。二元线性组合在空间上面实际上就是一个平面。图中就是要用该平面来拟合训练集的样本点的分布形式。θ可以理解为权重向量。

对于所有的机器学习来说，学习模式都是类似的：从一个训练集中，通过某种学习方法，去学习到一个映射的关系（f）。在有新的特征（x）输入了之后，可以通过学习到的映射关系（f），得到一个预估结果（y）。不同的机器学习算法，其映射关系表达形式也不同。在线性回归当中：

![](C:\ML-Excercise\pictures\chapter2\线性回归6.png)



我们希望找到最好的权重/参数θ向量。如何去衡量这个好与不好？定义**损失函数**：

![](C:\ML-Excercise\pictures\chapter2\线性回归7.png)

要使得能最好拟合训练样本，需要最小化损失函数。

> 对于一元
>
> ![](C:\ML-Excercise\pictures\chapter2\线性回归8.png)
>
> 对于多元
>
> ![](C:\ML-Excercise\pictures\chapter2\线性回归9.png)

如何求使J(θ)最小时θ的值？**梯度下降**

沿着损失函数梯度方向逐步修改参数。

> ![](C:\ML-Excercise\pictures\chapter2\线性回归10.png)
>
> ![](C:\ML-Excercise\pictures\chapter2\线性回归11.png)
>
> 式中α为梯度下降的学习率。太小收敛速度太慢，太大则会震荡甚至会不收敛。

**欠拟合与过拟合**

> **欠拟合**：模型没有很好地捕捉到数据特征，不能够很好的拟合数据。
>
> **过拟合**：把样本的一些噪声特性也学习下来了，泛化能力差。
>
> ![](C:\ML-Excercise\pictures\chapter2\线性回归12.png)
>
> 最左为欠拟合，最右为过拟合。
>
> - 更多的参数/特征，更复杂的模型，通常有更强的学习能力，但是更容易“失去控制”。
> - 训练集中有一些噪声，并不代表全量真实数据的分布，死记硬背会丧失泛化能力。

**过拟合与正则化**

通过正则化添加“惩罚参数”，控制参数幅度，限制参数搜索空间，减小过拟合风险。

![](C:\ML-Excercise\pictures\chapter2\线性回归13.png)

### 3 广义线性模型

对线性映射的结果进行数学变换，去逼近y值。（指数或对数变换处理）

![](C:\ML-Excercise\pictures\chapter2\线性回归14.png)

## 逻辑回归

分类问题，若使用*线性回归+阈值*去解决

![](C:\ML-Excercise\pictures\chapter2\逻辑回归1.png)

